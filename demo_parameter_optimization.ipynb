{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBF approximant with optimized parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo is a repetition of `demo_interpolation`, but with parameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_graph\n",
    "from graph_loaders import load_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from approx import GBFInterpolant\n",
    "from kernels import VarSpline, Diffusion\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading a pre-defined graph to be used as an example. \n",
    "\n",
    "All the following graphs have coordinate information for each node (as an attribute `pos` scaled to `[0, 1]^2`) that is used for visualization purposes. However, this information is not necessary nor used in the approximation process, since the main code only assumes that `G` is a `networkx` graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = load_graph('wbc')\n",
    "# G = load_graph('sensor2')\n",
    "# G = load_graph('sensor1')\n",
    "# G = load_graph('emptyset')\n",
    "# G = load_graph('2moon')\n",
    "# G = load_graph('minnesota')\n",
    "# G = load_graph('rand')\n",
    "# G = load_graph('rand_sparse')\n",
    "G = load_graph('bunny')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a training and a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a signal/function on the nodes using the `pos` attribute. This is an interesting test as the approximation process does not have access to this attribute, and it tries to reconstruct the signal by using only information on the nodes' connectivity.\n",
    "\n",
    "The signal `f` is defined as a Gaussian centered and scaled around the mean point of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: np.exp(-(4 * np.linalg.norm(x - [.5, .5], axis=1)) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract a random subset of 10% of the nodes to be used as the training set, and as a test set we use the entire set of nodes. All nodes sets are represented by the list of their indices in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(G) * 0.1)\n",
    "X_train = np.random.randint(1, len(G), size=n_train)\n",
    "X_test = np.arange(len(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we assign the train and test values by evaluating `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.array([[pos[0], pos[1]] for pos in nx.get_node_attributes(G, 'pos').values()])\n",
    "\n",
    "y_test = np.array(f(pos))\n",
    "y_train = y_test[X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the parameters and reconstruct the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define a metric to rank the performances of the different parameters. In this case the best model is the one providing the smallest mean error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "scorer = make_scorer(mean_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then specify the parameter grid to be evaluated. To optimize both the kernel parameter and the regularization parameter with a fixed kernel, it is sufficient to specify the range of each single parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#         'reg_par': np.logspace(-15, 0, 5),\n",
    "#         'kernel_par': [[-x] for x in np.logspace(-1, 2, 5)]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For kernels with multiple `kernel_par` it is possible to use instead something like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#         'reg_par': np.logspace(-15, 0, 5),\n",
    "#         'kernel_par': [[-x, y] for x in np.logspace(-1, 2, 5) for y in np.linspace(0, 10, 5)]\n",
    "#         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we treat also the kernel as a parameter to be optimized. Since different kernels may have different parameter number and range, we explicitly build the `params` serch grid by discretizing each parameter with `n_grid` samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grid = 5\n",
    "\n",
    "# Grid for the Diffusion kernel\n",
    "kernel = [['Diffusion']]\n",
    "reg_par = [[x] for x in np.logspace(-15, 0, n_grid)]\n",
    "kernel_par = [[-x] for x in np.logspace(-1, 2, n_grid)]\n",
    "params_1 = [{'kernel': kernel, 'reg_par' : reg_par, 'kernel_par': kernel_par}\n",
    "                   for kernel, reg_par, kernel_par in product(kernel, reg_par, kernel_par)]\n",
    "\n",
    "# Grid for the VarSpline kernel\n",
    "kernel = [['VarSpline']]\n",
    "reg_par = [[x] for x in np.logspace(-15, 0, n_grid)]\n",
    "kernel_par = [[-x, y] for x in np.logspace(-1, 2, 5) for y in np.linspace(0, 10, n_grid)]\n",
    "params_2 = [{'kernel': kernel, 'reg_par' : reg_par, 'kernel_par': kernel_par}\n",
    "                   for kernel, reg_par, kernel_par in product(kernel, reg_par, kernel_par)]\n",
    "\n",
    "# Join the two grids\n",
    "params = params_1 + params_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we wrap the approximation model into a `GridSearchCV`. We use all the available cores and run `cv=5`-fold cross validation, with final refitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(GBFInterpolant(G, verbose=False), \n",
    "                     params, scoring=scorer, n_jobs=-1, cv=5, \n",
    "                     refit=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we visualize the selected parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model.cv_results_).sort_values(by='rank_test_score').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can compute the predictions on the test set exactly as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compute some errors. We use a clipping in the computation of the relative error to avoid dividing by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_err_tol = 1e-10\n",
    "abs_err_test = np.abs(y_test - s_test)\n",
    "rel_err_test = abs_err_test / np.clip(np.abs(y_test), rel_err_tol, np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we visualize some results: the original and the reconstructed signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plot_graph(G, ax=ax, values=y_test, nodelist=model.best_estimator_.ctrs_, \n",
    "           cb_label='Target signal')\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plot_graph(G, ax=ax, values=s_test, nodelist=model.best_estimator_.ctrs_, \n",
    "           cb_label='Reconstructed signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the absolute and relative test errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plot_graph(G, ax=ax, values=abs_err_test, nodelist=model.best_estimator_.ctrs_, \n",
    "           cb_label='Absolute Error', log_scale=True)\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plot_graph(G, ax=ax, values=rel_err_test, nodelist=model.best_estimator_.ctrs_, \n",
    "           cb_label='Relative Error (clipped to %2.2e)' % rel_err_tol, log_scale=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
