{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the computation of a GBF approximant via f-greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_graph\n",
    "from graph_loaders import load_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from approx import GBFGreedy\n",
    "from kernels import VarSpline, Diffusion\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading a pre-defined graph to be used as an example. \n",
    "\n",
    "All the following graphs have coordinate information for each node (as an attribute `pos` scaled to `[0, 1]^2`) that is used for visualization purposes. However, this information is not necessary nor used in the approximation process, since the main code only assumes that `G` is a `networkx` graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = load_graph('wbc')\n",
    "# G = load_graph('sensor2')\n",
    "# G = load_graph('sensor1')\n",
    "# G = load_graph('emptyset')\n",
    "# G = load_graph('2moon')\n",
    "# G = load_graph('minnesota')\n",
    "# G = load_graph('rand')\n",
    "# G = load_graph('rand_sparse')\n",
    "G = load_graph('bunny')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a training and a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a signal/function on the nodes using the `pos` attribute. This is an interesting test as the approximation process does not have access to this attribute, and it tries to reconstruct the signal by using only information on the nodes' connectivity.\n",
    "\n",
    "The signal `f` is defined as a Gaussian centered and scaled around the mean point of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: np.exp(-(4 * np.linalg.norm(x - [.5, .5], axis=1)) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract a random subset of 50% of the nodes to be used as the training set, and as a test set we use the entire set of nodes. All nodes sets are represented by the list of their indices in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(G) * 0.1)\n",
    "X_train = np.random.randint(1, len(G), size=n_train)\n",
    "X_test = np.arange(len(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we assign the train and test values by evaluating `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.array([[pos[0], pos[1]] for pos in nx.get_node_attributes(G, 'pos').values()])\n",
    "\n",
    "y_test = np.array(f(pos))\n",
    "y_train = y_test[X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signal looks as follows. The training nodes are highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "fig.clf()\n",
    "ax = fig.gca()\n",
    "plot_graph(G, ax=ax, values=y_test, nodelist=X_train, \n",
    "           cb_label='Target signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now pick a Graph Basis Function as the kernel that will be used in the approximation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = VarSpline(G, par=[-1.1, 0.01])\n",
    "kernel = Diffusion(G, par=[-10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first initialize the approximant. Here we require that at most `80%` of the training points are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = int(len(X_train) * 0.8)\n",
    "\n",
    "model = GBFGreedy(G, kernel=kernel, greedy_type='f_greedy', \n",
    "                  reg_par=1e-15, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit the approximant to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can compute the predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compute some errors. We use a clipping in the computation of the relative error to avoid dividing by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_err_tol = 1e-10\n",
    "abs_err_test = np.abs(y_test - s_test)\n",
    "rel_err_test = abs_err_test / np.clip(np.abs(y_test), rel_err_tol, np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_max, p_max = model.train_hist['f'], model.train_hist['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.loglog(f_max)\n",
    "ax.set_xlabel('Number of nodes', fontsize=16)\n",
    "ax.set_ylabel('Max error (on training set)', fontsize=16)\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(16) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(16) \n",
    "ax.grid(True)\n",
    "\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ax.loglog(p_max)\n",
    "ax.set_xlabel('Number of nodes', fontsize=16)\n",
    "ax.set_ylabel('Max power function (on training set)', fontsize=16)\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(16) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(16) \n",
    "ax.grid(True)\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we visualize the original and the reconstructed signal. Observe that in this case the marked nodes are the ones selected by the greedy algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plot_graph(G, ax=ax, values=y_test, nodelist=model.ctrs_, \n",
    "           cb_label='Target signal')\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plot_graph(G, ax=ax, values=s_test, nodelist=model.ctrs_, \n",
    "           cb_label='Reconstructed signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the absolute and relative test errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plot_graph(G, ax=ax, values=abs_err_test, nodelist=model.ctrs_, \n",
    "           cb_label='Absolute Error', log_scale=True)\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plot_graph(G, ax=ax, values=rel_err_test, nodelist=model.ctrs_, \n",
    "           cb_label='Relative Error (clipped to %2.2e)' % rel_err_tol, log_scale=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
